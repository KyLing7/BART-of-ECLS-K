{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa86f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功，共 7362 行 × 13 列，文件名：final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"eclsk.csv\")\n",
    "\n",
    "cols = [\n",
    "    \"CHILDID\",     \n",
    "    \"avg_MIRT\",     \n",
    "    \"P1HSEVER\",     \n",
    "    \"GENDER\", \"WKWHITE\", \"WKSESL\", \"S2KPUPRI\", \"apprchT1\",\n",
    "    \"P1FSTAMP\", \"ONEPARENT\", \"WKCAREPK\", \"P1HSCALE\", \"P1SADLON\"\n",
    "]\n",
    "\n",
    "df_final = df[cols].copy().dropna()\n",
    "\n",
    "df_final.to_csv(\"final.csv\", index=False)\n",
    "print(f\"保存成功，共 {df_final.shape[0]} 行 × {df_final.shape[1]} 列，文件名：final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSM 匹配后的 ATE：-0.9170\n",
      "PSM + 回归调整后的 ATE：-0.6947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "\n",
    "y = df[\"avg_MIRT\"].values\n",
    "T = df[\"P1HSEVER\"].values\n",
    "X = df[[\"GENDER\", \"WKWHITE\", \"WKSESL\", \"S2KPUPRI\", \"apprchT1\",\n",
    "        \"P1FSTAMP\", \"ONEPARENT\", \"WKCAREPK\", \"P1HSCALE\", \"P1SADLON\"]].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "ps_model = LogisticRegression(solver='liblinear')\n",
    "ps_model.fit(X_scaled, T)\n",
    "propensity_scores = ps_model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "treated_idx = np.where(T == 1)[0]\n",
    "control_idx = np.where(T == 0)[0]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(propensity_scores[control_idx].reshape(-1, 1))\n",
    "distances, matched_control_idx = nn.kneighbors(propensity_scores[treated_idx].reshape(-1, 1))\n",
    "\n",
    "treated_y = y[treated_idx]\n",
    "matched_y = y[control_idx][matched_control_idx.flatten()]\n",
    "\n",
    "ate_psm = np.mean(treated_y - matched_y)\n",
    "print(f\"PSM 匹配后的 ATE：{ate_psm:.4f}\")\n",
    "\n",
    "X_matched = X_scaled[treated_idx]\n",
    "reg = LinearRegression().fit(X_matched, treated_y - matched_y)\n",
    "adj_effect = reg.intercept_\n",
    "print(f\"PSM + 回归调整后的 ATE：{adj_effect:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5db188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting burn\n",
      "Starting burn\n",
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 46.07it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 45.63it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 46.24it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 45.77it/s]\n",
      "  2%|▎         | 5/200 [00:00<00:04, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n",
      "Starting sampling\n",
      "Starting sampling\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 46.72it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 46.35it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 46.24it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 46.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:00<00:20,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 28.39it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 27.58it/s]\n",
      " 98%|█████████▊| 195/200 [00:07<00:00, 29.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.89it/s]\n",
      "  6%|▌         | 11/200 [00:00<00:06, 30.54it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.03it/s]\n",
      "  2%|▏         | 3/200 [00:00<00:06, 29.58it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 29.42it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 28.58it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 28.91it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 28.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART 估计的 ATE：-1.5552\n",
      "\n",
      "按 SES 分组的 CATE（BART）：\n",
      "SES_group\n",
      "Low      -1.021495\n",
      "Medium   -1.431851\n",
      "High     -2.217473\n",
      "Name: ITE, dtype: float64\n",
      "\n",
      "ITE 结果已保存为 ite_results.csv ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_3qg9gs11jjc7473nnygd52r0000gn/T/ipykernel_55405/3386521670.py:50: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = df.groupby(\"SES_group\")[\"ITE\"].mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bartpy.sklearnmodel import SklearnModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "\n",
    "y = df[\"avg_MIRT\"].values           \n",
    "T = df[\"P1HSEVER\"].values                    \n",
    "X = df.drop(columns=[\"CHILDID\", \"avg_MIRT\", \"P1HSEVER\"]).values  \n",
    "child_ids = df[\"CHILDID\"].values\n",
    "ses = df[\"WKSESL\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model_treated = SklearnModel()\n",
    "model_control = SklearnModel()\n",
    "\n",
    "model_treated.fit(X_scaled[T == 1], y[T == 1])\n",
    "model_control.fit(X_scaled[T == 0], y[T == 0])\n",
    "\n",
    "mu1 = model_treated.predict(X_scaled)\n",
    "mu0 = model_control.predict(X_scaled)\n",
    "ite = mu1 - mu0\n",
    "ate = np.mean(ite)\n",
    "print(f\"BART 估计的 ATE：{ate:.4f}\")\n",
    "\n",
    "df[\"ITE\"] = ite\n",
    "df[\"SES\"] = ses\n",
    "df[\"SES_group\"] = pd.qcut(df[\"SES\"], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "grouped = df.groupby(\"SES_group\")[\"ITE\"].mean()\n",
    "print(\"\\n按 SES 分组的 CATE（BART）：\")\n",
    "print(grouped)\n",
    "\n",
    "ite_df = df[[\"CHILDID\", \"avg_MIRT\", \"P1HSEVER\", \"ITE\"]]\n",
    "ite_df.to_csv(\"ite_results.csv\", index=False)\n",
    "print(\"\\nITE 结果已保存为 ite_results.csv ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a03d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal Forest 估计的 ATE：-2.4340\n",
      "\n",
      "按 SES 分组的 CATE（Causal Forest）：\n",
      "SES_group\n",
      "Low      -1.811747\n",
      "Medium   -2.792857\n",
      "High     -2.701769\n",
      "Name: ITE_CF, dtype: float64\n",
      "\n",
      "特征重要性（feature importances）：\n",
      "GENDER: 0.0031\n",
      "WKWHITE: 0.0238\n",
      "WKSESL: 0.6637\n",
      "S2KPUPRI: 0.2727\n",
      "apprchT1: 0.0080\n",
      "P1FSTAMP: 0.0253\n",
      "ONEPARENT: 0.0000\n",
      "WKCAREPK: 0.0000\n",
      "P1HSCALE: 0.0024\n",
      "P1SADLON: 0.0008\n",
      "\n",
      "结果保存为 causal_forest_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_3qg9gs11jjc7473nnygd52r0000gn/T/ipykernel_85602/426320270.py:38: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cate_grouped = df.groupby(\"SES_group\")[\"ITE_CF\"].mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from econml.grf import CausalForest\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "\n",
    "y = df[\"avg_MIRT\"].values\n",
    "T = df[\"P1HSEVER\"].values\n",
    "X = df[[\"GENDER\", \"WKWHITE\", \"WKSESL\", \"S2KPUPRI\", \"apprchT1\",\n",
    "        \"P1FSTAMP\", \"ONEPARENT\", \"WKCAREPK\", \"P1HSCALE\", \"P1SADLON\"]]\n",
    "child_ids = df[\"CHILDID\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = CausalForest(\n",
    "    n_estimators=500,\n",
    "    min_samples_leaf=50,\n",
    "    min_samples_split=100,\n",
    "    max_depth=5,\n",
    "    min_weight_fraction_leaf=0.1,\n",
    "    random_state=42,\n",
    "    honest=False\n",
    ")\n",
    "\n",
    "model.fit(X=X_scaled, y=y, T=T)\n",
    "\n",
    "ite = model.predict(X_scaled)\n",
    "\n",
    "ate = np.mean(ite)\n",
    "print(f\"Causal Forest 估计的 ATE：{ate:.4f}\")\n",
    "\n",
    "df[\"ITE_CF\"] = ite\n",
    "\n",
    "df[\"SES\"] = df[\"WKSESL\"]\n",
    "df[\"SES_group\"] = pd.qcut(df[\"SES\"], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "cate_grouped = df.groupby(\"SES_group\")[\"ITE_CF\"].mean()\n",
    "print(\"\\n按 SES 分组的 CATE（Causal Forest）：\")\n",
    "print(cate_grouped)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "print(\"\\n特征重要性（feature importances）：\")\n",
    "for name, val in zip(X.columns, importances):\n",
    "    print(f\"{name}: {val:.4f}\")\n",
    "\n",
    "df.to_csv(\"causal_forest_results.csv\", index=False)\n",
    "print(\"\\n结果保存为 causal_forest_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0ad4d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ite_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m bart_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mite_results.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m bart_df \u001b[38;5;241m=\u001b[39m bart_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHILDID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mITE\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mITE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mITE_BART\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      6\u001b[0m cf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal_forest_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ite_results.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bart_df = pd.read_csv(\"ite_results.csv\")\n",
    "bart_df = bart_df[[\"CHILDID\", \"ITE\"]].rename(columns={\"ITE\": \"ITE_BART\"})\n",
    "\n",
    "cf_df = pd.read_csv(\"causal_forest_results.csv\") \n",
    "cf_df = cf_df[[\"CHILDID\", \"ITE_CF\"]].rename(columns={\"ITE_CF\": \"ITE_CF\"})\n",
    "\n",
    "merged_df = pd.merge(bart_df, cf_df, on=\"CHILDID\", how=\"inner\")\n",
    "\n",
    "merged_df.to_csv(\"ite_comparison_bart_vs_cf.csv\", index=False)\n",
    "\n",
    "print(\"成功生成 ITE 对比文件：ite_comparison_bart_vs_cf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaa9a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:00<00:06, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting burn\n",
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:00<00:04, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 44.40it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 44.29it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n",
      "Starting sampling\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 44.15it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 45.41it/s]\n",
      " 10%|█         | 20/200 [00:00<00:03, 46.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 45.09it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 45.60it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 44.95it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:12, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n",
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:00<00:08, 22.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting burn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.70it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n",
      "Starting sampling\n",
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 25.47it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 26.29it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 26.96it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 28.87it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 27.49it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 28.63it/s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 26.42it/s]\n",
      "/var/folders/j3/_3qg9gs11jjc7473nnygd52r0000gn/T/ipykernel_85602/2849687230.py:43: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cate_by_ses = results_df.groupby(\"SES_group\")[\"ITE\"].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BART结果汇总：\n",
      "BART ATE：-1.5401\n",
      "SES 分组下的 CATE：\n",
      "  • Low SES：-0.9593\n",
      "  • Medium SES：-1.5397\n",
      "  • High SES：-2.1265\n",
      "\n",
      " 所有结果与图像已成功生成：\n",
      " - bart_ite_individuals.csv\n",
      " - bart_summary_ate_cate.csv\n",
      " - fig1_bart_ite_histogram.png\n",
      " - fig2_bart_cate_by_ses.png\n",
      " - fig3_bart_ite_vs_ses.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bartpy.sklearnmodel import SklearnModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "y = df[\"avg_MIRT\"].values\n",
    "T = df[\"P1HSEVER\"].values\n",
    "X = df.drop(columns=[\"CHILDID\", \"avg_MIRT\", \"P1HSEVER\"])\n",
    "child_ids = df[\"CHILDID\"].values\n",
    "ses = df[\"WKSESL\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model_treated = SklearnModel()\n",
    "model_control = SklearnModel()\n",
    "\n",
    "model_treated.fit(X_scaled[T == 1], y[T == 1])\n",
    "model_control.fit(X_scaled[T == 0], y[T == 0])\n",
    "\n",
    "mu1 = model_treated.predict(X_scaled)\n",
    "mu0 = model_control.predict(X_scaled)\n",
    "ite = mu1 - mu0\n",
    "ate = np.mean(ite)\n",
    "\n",
    "ses_group = pd.qcut(ses, q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "results_df = pd.DataFrame({\n",
    "    \"CHILDID\": child_ids,\n",
    "    \"avg_MIRT\": y,\n",
    "    \"P1HSEVER\": T,\n",
    "    \"ITE\": ite,\n",
    "    \"WKSESL\": ses,\n",
    "    \"SES_group\": ses_group\n",
    "})\n",
    "\n",
    "cate_by_ses = results_df.groupby(\"SES_group\")[\"ITE\"].mean()\n",
    "cate_low = cate_by_ses[\"Low\"]\n",
    "cate_med = cate_by_ses[\"Medium\"]\n",
    "cate_high = cate_by_ses[\"High\"]\n",
    "\n",
    "print(\"\\nBART结果汇总：\")\n",
    "print(f\"BART ATE：{ate:.4f}\")\n",
    "print(\"SES 分组下的 CATE：\")\n",
    "print(f\"  • Low SES：{cate_low:.4f}\")\n",
    "print(f\"  • Medium SES：{cate_med:.4f}\")\n",
    "print(f\"  • High SES：{cate_high:.4f}\")\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Metric\": [\"ATE\", \"CATE_Low\", \"CATE_Medium\", \"CATE_High\"],\n",
    "    \"Value\": [ate, cate_low, cate_med, cate_high]\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"bart_ite_individuals.csv\", index=False)\n",
    "summary_df.to_csv(\"bart_summary_ate_cate.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(ite, bins=30, edgecolor='black')\n",
    "plt.axvline(x=ate, color='red', linestyle='--', label=f'ATE = {ate:.2f}')\n",
    "plt.title(\"Figure 1. Distribution of Individual Treatment Effects (BART)\")\n",
    "plt.xlabel(\"ITE Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig1_bart_ite_histogram.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "cate_by_ses.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.ylabel(\"CATE\")\n",
    "plt.title(\"Figure 2. CATE by Socioeconomic Status Group (BART)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig2_bart_cate_by_ses.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.regplot(x=results_df[\"WKSESL\"], y=results_df[\"ITE\"], scatter_kws={'alpha':0.3})\n",
    "plt.xlabel(\"Socioeconomic Status (WKSESL)\")\n",
    "plt.ylabel(\"Individual Treatment Effect (ITE)\")\n",
    "plt.title(\"Figure 3. ITE vs. SES (BART)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig3_bart_ite_vs_ses.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n 所有结果与图像已成功生成：\")\n",
    "print(\" - bart_ite_individuals.csv\")\n",
    "print(\" - bart_summary_ate_cate.csv\")\n",
    "print(\" - fig1_bart_ite_histogram.png\")\n",
    "print(\" - fig2_bart_cate_by_ses.png\")\n",
    "print(\" - fig3_bart_ite_vs_ses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb935d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_3qg9gs11jjc7473nnygd52r0000gn/T/ipykernel_85602/4294155208.py:35: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cate_grouped = df.groupby(\"SES_group\")[\"ITE_CF\"].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 因果森林（Causal Forest）结果汇总：\n",
      "CF ATE：-2.4340\n",
      "SES 分组下的 CATE：\n",
      "  • Low SES：-1.8117\n",
      "  • Medium SES：-2.7929\n",
      "  • High SES：-2.7018\n",
      "\n",
      " 所有 Causal Forest 结果与图表已保存：\n",
      " - causal_forest_results_small_sample.csv\n",
      " - fig4_cf_ite_histogram.png\n",
      " - fig5_cf_cate_by_ses.png\n",
      " - fig6_cf_feature_importance.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/_3qg9gs11jjc7473nnygd52r0000gn/T/ipykernel_85602/4294155208.py:72: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Importance\", y=\"Variable\", data=feature_df, palette=\"viridis\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from econml.grf import CausalForest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "y = df[\"avg_MIRT\"].values\n",
    "T = df[\"P1HSEVER\"].values\n",
    "X = df[[\"GENDER\", \"WKWHITE\", \"WKSESL\", \"S2KPUPRI\", \"apprchT1\",\n",
    "        \"P1FSTAMP\", \"ONEPARENT\", \"WKCAREPK\", \"P1HSCALE\", \"P1SADLON\"]]\n",
    "child_ids = df[\"CHILDID\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = CausalForest(\n",
    "    n_estimators=500,\n",
    "    min_samples_leaf=50,\n",
    "    min_samples_split=100,\n",
    "    max_depth=5,\n",
    "    min_weight_fraction_leaf=0.1,\n",
    "    random_state=42,\n",
    "    honest=False\n",
    ")\n",
    "model.fit(X=X_scaled, y=y, T=T)\n",
    "\n",
    "ite = model.predict(X_scaled)\n",
    "ate = np.mean(ite)\n",
    "\n",
    "df[\"ITE_CF\"] = ite\n",
    "df[\"SES\"] = df[\"WKSESL\"]\n",
    "df[\"SES_group\"] = pd.qcut(df[\"SES\"], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "cate_grouped = df.groupby(\"SES_group\")[\"ITE_CF\"].mean()\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_df = pd.DataFrame({\n",
    "    \"Variable\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\n 因果森林（Causal Forest）结果汇总：\")\n",
    "print(f\"CF ATE：{ate:.4f}\")\n",
    "print(\"SES 分组下的 CATE：\")\n",
    "for grp, val in cate_grouped.items():\n",
    "    print(f\"  • {grp} SES：{val:.4f}\")\n",
    "\n",
    "df.to_csv(\"causal_forest_results_small_sample.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df[\"ITE_CF\"], bins=30, edgecolor='black')\n",
    "plt.axvline(x=ate, color='red', linestyle='--', label=f'ATE = {ate:.2f}')\n",
    "plt.title(\"Figure 4. Distribution of Individual Treatment Effects (Causal Forest)\")\n",
    "plt.xlabel(\"ITE Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig4_cf_ite_histogram.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "cate_grouped.plot(kind='bar', color='lightgreen', edgecolor='black')\n",
    "plt.ylabel(\"CATE\")\n",
    "plt.title(\"Figure 5. CATE by Socioeconomic Status Group (Causal Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig5_cf_cate_by_ses.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=\"Importance\", y=\"Variable\", data=feature_df, palette=\"viridis\")\n",
    "plt.title(\"Figure 6. Feature Importances (Causal Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig6_cf_feature_importance.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n 所有 Causal Forest 结果与图表已保存：\")\n",
    "print(\" - causal_forest_results_small_sample.csv\")\n",
    "print(\" - fig4_cf_ite_histogram.png\")\n",
    "print(\" - fig5_cf_cate_by_ses.png\")\n",
    "print(\" - fig6_cf_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c777388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PSM 估计结果：\n",
      "  • 匹配后 ATE：-1.2158\n",
      "  • 匹配 + 回归调整 ATE：-1.2606\n",
      "\n",
      " 已保存：psm_matched_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"final.csv\")\n",
    "y = df[\"avg_MIRT\"].values\n",
    "T = df[\"P1HSEVER\"].values\n",
    "X = df[[\"GENDER\", \"WKWHITE\", \"WKSESL\", \"S2KPUPRI\", \"apprchT1\",\n",
    "        \"P1FSTAMP\", \"ONEPARENT\", \"WKCAREPK\", \"P1HSCALE\", \"P1SADLON\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "ps_model = LogisticRegression()\n",
    "ps_model.fit(X_scaled, T)\n",
    "ps = ps_model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "treated_idx = np.where(T == 1)[0]\n",
    "control_idx = np.where(T == 0)[0]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(ps[control_idx].reshape(-1, 1))\n",
    "distances, matched_control_idx = nn.kneighbors(ps[treated_idx].reshape(-1, 1))\n",
    "\n",
    "treated_y = y[treated_idx]\n",
    "matched_control_y = y[control_idx][matched_control_idx.flatten()]\n",
    "ate_matched = np.mean(treated_y - matched_control_y)\n",
    "\n",
    "matched_treated_X = X_scaled[treated_idx]\n",
    "matched_control_X = X_scaled[control_idx][matched_control_idx.flatten()]\n",
    "matched_X = np.vstack([matched_treated_X, matched_control_X])\n",
    "matched_T = np.hstack([np.ones(len(treated_idx)), np.zeros(len(matched_control_idx))])\n",
    "matched_Y = np.hstack([treated_y, matched_control_y])\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(np.column_stack([matched_T, matched_X]), matched_Y)\n",
    "ate_regression = reg.coef_[0]\n",
    "\n",
    "print(\"\\n PSM 估计结果：\")\n",
    "print(f\"  • 匹配后 ATE：{ate_matched:.4f}\")\n",
    "print(f\"  • 匹配 + 回归调整 ATE：{ate_regression:.4f}\")\n",
    "\n",
    "matched_df = pd.DataFrame(matched_X, columns=X.columns)\n",
    "matched_df[\"T\"] = matched_T\n",
    "matched_df[\"Y\"] = matched_Y\n",
    "matched_df.to_csv(\"psm_matched_results.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "bars = plt.bar([\"Matched\", \"Matched + Regression\"],\n",
    "               [ate_matched, ate_regression],\n",
    "               color=[\"lightblue\", \"steelblue\"])\n",
    "\n",
    "plt.ylim(-1.4, 0)\n",
    "plt.ylabel(\"Average Treatment Effect (ATE)\")\n",
    "plt.title(\"Figure 7. ATE Estimates from PSM\")\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.02,\n",
    "             f\"{height:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig7_psm_ate_comparison.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n 已保存：psm_matched_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3661be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711aa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f1b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
